{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a88fabb",
   "metadata": {},
   "source": [
    "Step 1: Setup and Environment\n",
    "First, create a new Jupyter notebook and add a markdown cell with your project title and description.\n",
    "\n",
    "Then, add a code cell for imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a364fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version\n",
    "!pip install umap-learn scanpy scipy anndata leidenalg python-igraph louvain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2da39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "# SC analysis\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "# dr methods\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "\n",
    "# evaluation metrics\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# talked about the configuration in the report\n",
    "sc.settings.verbosity = 3\n",
    "sc.settings.set_figure_params(dpi=100, facecolor='white', frameon=True)\n",
    "\n",
    "try:\n",
    "    sc.logging.print_header()\n",
    "except Exception as e:\n",
    "    print(f\"Note: Could not print scanpy header: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9012422",
   "metadata": {},
   "source": [
    "Step 2: Data Acquisition\n",
    "Add a code cell to download and load datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0041fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(download_path=\"data\"):\n",
    "    \"\"\"Download and prepare datasets for analysis\"\"\"\n",
    "    \n",
    "    os.makedirs(download_path, exist_ok=True)\n",
    "    \n",
    "    # PBMC\n",
    "    try:\n",
    "        pbmc = sc.read_h5ad(os.path.join(download_path, \"pbmc3k.h5ad\"))\n",
    "        print(\"PBMC dataset loaded from file.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Downloading PBMC dataset...\")\n",
    "        pbmc = sc.datasets.pbmc3k()\n",
    "        pbmc.write_h5ad(os.path.join(download_path, \"pbmc3k.h5ad\"))\n",
    "    \n",
    "    # Developmental trajectory\n",
    "    try:\n",
    "        trajectory = sc.read_h5ad(os.path.join(download_path, \"paul15.h5ad\"))\n",
    "        print(\"Paul et al. trajectory dataset loaded from file.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Downloading Paul et al. trajectory dataset...\")\n",
    "        trajectory = sc.datasets.paul15()\n",
    "        trajectory.write_h5ad(os.path.join(download_path, \"paul15.h5ad\"))\n",
    "    \n",
    "    return pbmc, trajectory\n",
    "\n",
    "\n",
    "pbmc_data, trajectory_data = get_datasets()\n",
    "\n",
    "# info about datasets\n",
    "print(\"\\nPBMC dataset summary:\")\n",
    "print(f\"Shape: {pbmc_data.shape}\")\n",
    "print(f\"Available annotations: {list(pbmc_data.obs.columns)}\")\n",
    "\n",
    "print(\"\\nTrajectory dataset summary:\")\n",
    "print(f\"Shape: {trajectory_data.shape}\")\n",
    "print(f\"Available annotations: {list(trajectory_data.obs.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8c0c19",
   "metadata": {},
   "source": [
    "Step 3: Data Preprocessing Function\n",
    "Add a preprocessing function in a new code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce3709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(adata, min_genes=200, min_cells=3, \n",
    "                   target_sum=1e4, n_top_genes=5000,\n",
    "                   quick_run=False):\n",
    "    \"\"\"\n",
    "    Preprocess AnnData object for dimensionality reduction\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    adata : AnnData\n",
    "        AnnData object to preprocess\n",
    "    min_genes : int\n",
    "        Minimum number of genes per cell\n",
    "    min_cells : int\n",
    "        Minimum number of cells per gene\n",
    "    target_sum : float\n",
    "        Target sum for normalization\n",
    "    n_top_genes : int\n",
    "        Number of highly variable genes to select\n",
    "    quick_run : bool\n",
    "        If True, subset to 1000 cells for quicker testing\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    AnnData\n",
    "        Preprocessed data\n",
    "    \"\"\"\n",
    "    print(f\"Starting preprocessing with {adata.shape[0]} cells and {adata.shape[1]} genes\")\n",
    "    \n",
    "    adata = adata.copy()\n",
    "    \n",
    "    if quick_run and adata.shape[0] > 1000:\n",
    "        print(\"Subsampling to 1000 cells for quick run\")\n",
    "        sc.pp.subsample(adata, n_obs=1000, random_state=RANDOM_SEED)\n",
    "    \n",
    "    # QC filtering\n",
    "    sc.pp.filter_cells(adata, min_genes=min_genes)\n",
    "    sc.pp.filter_genes(adata, min_cells=min_cells)\n",
    "    \n",
    "    # QC metrics\n",
    "    sc.pp.calculate_qc_metrics(adata, inplace=True)\n",
    "\n",
    "    # mitochondrial gene percentage\n",
    "    mito_prefixes = ['MT-', 'mt-', 'Mt-']\n",
    "    has_mito = False\n",
    "\n",
    "    for prefix in mito_prefixes:\n",
    "        if any(adata.var_names.str.startswith(prefix)):\n",
    "            adata.var['mt'] = adata.var_names.str.startswith(prefix)\n",
    "            has_mito = True\n",
    "            print(f\"Found mitochondrial genes with prefix: {prefix}\")\n",
    "            break\n",
    "\n",
    "    if not has_mito:\n",
    "        print(\"No mitochondrial genes found with standard prefixes\")\n",
    "        adata.var['mt'] = False\n",
    "    \n",
    "    sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, inplace=True)\n",
    "    \n",
    "    adata.obs['pct_counts_mt'] = adata.obs['pct_counts_mt']\n",
    "    \n",
    "    # normalizaion - (Not Poisson/NB, but I talked about this in the report)\n",
    "    sc.pp.normalize_total(adata, target_sum=target_sum)\n",
    "    sc.pp.log1p(adata)\n",
    "    \n",
    "    # hvg\n",
    "    sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)\n",
    "    \n",
    "    # subset to hvg\n",
    "    adata = adata[:, adata.var.highly_variable]\n",
    "    \n",
    "    # scaleing\n",
    "    sc.pp.scale(adata, max_value=10)\n",
    "    \n",
    "    print(f\"Finished preprocessing: {adata.shape[0]} cells and {adata.shape[1]} genes remain\")\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1bd009",
   "metadata": {},
   "source": [
    "Step 4: Preprocessing the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9cfbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUICK_RUN = False\n",
    "\n",
    "pbmc_processed = preprocess_data(pbmc_data, quick_run=QUICK_RUN)\n",
    "trajectory_processed = preprocess_data(trajectory_data, quick_run=QUICK_RUN)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# PBMC QC plots\n",
    "sns.violinplot(y=pbmc_processed.obs['n_genes'], ax=axes[0, 0])\n",
    "sns.violinplot(y=pbmc_processed.obs['total_counts'], ax=axes[0, 1])\n",
    "sns.violinplot(y=pbmc_processed.obs['pct_counts_mt'], ax=axes[0, 2])\n",
    "axes[0, 0].set_title('PBMC: Genes per Cell')\n",
    "axes[0, 1].set_title('PBMC: Counts per Cell')\n",
    "axes[0, 2].set_title('PBMC: % Mitochondrial')\n",
    "\n",
    "# trajectory QC plots\n",
    "sns.violinplot(y=trajectory_processed.obs['n_genes'], ax=axes[1, 0])\n",
    "sns.violinplot(y=trajectory_processed.obs['total_counts'], ax=axes[1, 1])\n",
    "axes[1, 0].set_title('Trajectory: Genes per Cell')\n",
    "axes[1, 1].set_title('Trajectory: Counts per Cell')\n",
    "axes[1, 2].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52338c99",
   "metadata": {},
   "source": [
    "Step 5: Dimensionality Reduction Functions\n",
    "Add a cell with dimensionality reduction functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5e2fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_pca(adata, n_comps=[10, 20, 50, 100], use_hvg=True):\n",
    "    results = {}\n",
    "    \n",
    "    data = adata.copy()\n",
    "    \n",
    "    for n_comp in n_comps:\n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        # limit to max possible components\n",
    "        actual_n_comp = min(n_comp, data.shape[0] - 1, data.shape[1])\n",
    "        \n",
    "        print(f\"Running PCA with {actual_n_comp} components...\")\n",
    "        sc.pp.pca(data, n_comps=actual_n_comp, use_highly_variable=use_hvg, random_state=RANDOM_SEED)\n",
    "        \n",
    "        end_time = time.perf_counter()\n",
    "        runtime = end_time - start_time\n",
    "        \n",
    "        results[n_comp] = {\n",
    "            'embedding': data.obsm['X_pca'].copy(),\n",
    "            'runtime': runtime,\n",
    "            'variance_ratio': data.uns['pca']['variance_ratio']\n",
    "        }\n",
    "        \n",
    "        print(f\"PCA with {actual_n_comp} components completed in {runtime:.2f} seconds\")\n",
    "        \n",
    "    return results\n",
    "\n",
    "def run_tsne(adata, perplexities=[5, 30, 50], n_pca=50, random_seeds=[42, 123, 456]):\n",
    "    results = {}\n",
    "    \n",
    "    data = adata.copy()\n",
    "    if 'X_pca' not in data.obsm:\n",
    "        sc.pp.pca(data, n_comps=n_pca, random_state=RANDOM_SEED)\n",
    "    \n",
    "    for perplexity in perplexities:\n",
    "        results[perplexity] = {'embeddings': [], 'runtimes': []}\n",
    "        \n",
    "        for seed in random_seeds:\n",
    "            print(f\"Running t-SNE with perplexity {perplexity}, seed {seed}...\")\n",
    "            \n",
    "            start_time = time.perf_counter()\n",
    "            \n",
    "            sc.tl.tsne(data, perplexity=perplexity, use_rep='X_pca', \n",
    "                       random_state=seed, n_jobs=4)\n",
    "            \n",
    "            end_time = time.perf_counter()\n",
    "            runtime = end_time - start_time\n",
    "            \n",
    "            results[perplexity]['embeddings'].append(data.obsm['X_tsne'].copy())\n",
    "            results[perplexity]['runtimes'].append(runtime)\n",
    "            \n",
    "            print(f\"t-SNE with perplexity {perplexity} completed in {runtime:.2f} seconds\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def run_umap(adata, n_neighbors_list=[5, 15, 30, 50], min_dist_list=[0.1, 0.5], n_pca=50):\n",
    "    results = {}\n",
    "    \n",
    "    data = adata.copy()\n",
    "    if 'X_pca' not in data.obsm:\n",
    "        sc.pp.pca(data, n_comps=n_pca, random_state=RANDOM_SEED)\n",
    "    \n",
    "    for n_neighbors in n_neighbors_list:\n",
    "        results[n_neighbors] = {}\n",
    "        \n",
    "        for min_dist in min_dist_list:\n",
    "            print(f\"Running UMAP with n_neighbors={n_neighbors}, min_dist={min_dist}...\")\n",
    "            \n",
    "            start_time = time.perf_counter()\n",
    "            \n",
    "            sc.pp.neighbors(data, n_neighbors=n_neighbors, use_rep='X_pca', random_state=RANDOM_SEED)\n",
    "            sc.tl.umap(data, min_dist=min_dist, random_state=RANDOM_SEED)\n",
    "            \n",
    "            end_time = time.perf_counter()\n",
    "            runtime = end_time - start_time\n",
    "            \n",
    "            results[n_neighbors][min_dist] = {\n",
    "                'embedding': data.obsm['X_umap'].copy(),\n",
    "                'runtime': runtime\n",
    "            }\n",
    "            \n",
    "            print(f\"UMAP with n_neighbors={n_neighbors}, min_dist={min_dist} completed in {runtime:.2f} seconds\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408ac9a9",
   "metadata": {},
   "source": [
    "Step 6: Running the Dimensionality Reduction Methods\n",
    "Add a cell to run the methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a0765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Running dimensionality reduction on PBMC data...\")\n",
    "\n",
    "pbmc_pca_results = run_pca(pbmc_processed, n_comps=[10, 20, 50, 100])\n",
    "pbmc_tsne_results = run_tsne(pbmc_processed, perplexities=[5, 30, 50])\n",
    "pbmc_umap_results = run_umap(pbmc_processed, n_neighbors_list=[5, 15, 30, 50], min_dist_list=[0.1, 0.5])\n",
    "\n",
    "print(\"\\nRunning dimensionality reduction on trajectory data...\")\n",
    "\n",
    "trajectory_pca_results = run_pca(trajectory_processed, n_comps=[10, 20, 50, 100])\n",
    "trajectory_tsne_results = run_tsne(trajectory_processed, perplexities=[5, 30, 50])\n",
    "trajectory_umap_results = run_umap(trajectory_processed, n_neighbors_list=[5, 15, 30, 50], min_dist_list=[0.1, 0.5])\n",
    "\n",
    "print(\"All dimensionality reduction methods completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b6ae35",
   "metadata": {},
   "source": [
    "Step 7: Evaluation Metrics\n",
    "Add a cell with evaluation metric functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e3b9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_clustering_preservation(embedding, labels):\n",
    "    \"\"\"\n",
    "    # how well clustering is preserved \n",
    "    # leiden clustering\n",
    "    \n",
    "    Returns ARI and NMI scores\n",
    "    \"\"\"\n",
    "    temp = ad.AnnData(X=np.zeros((embedding.shape[0], 1)))\n",
    "    temp.obsm['X_embedding'] = embedding\n",
    "    \n",
    "    sc.pp.neighbors(temp, use_rep='X_embedding')\n",
    "    \n",
    "    resolutions = [0.1, 0.3, 0.5, 0.8, 1.0, 1.5, 2.0]\n",
    "    best_ari = -1\n",
    "    best_nmi = -1\n",
    "    \n",
    "    for res in resolutions:\n",
    "        sc.tl.leiden(temp, resolution=res)\n",
    "        pred_labels = temp.obs['leiden'].astype(str).values\n",
    "        \n",
    "        ari = adjusted_rand_score(labels, pred_labels)\n",
    "        nmi = normalized_mutual_info_score(labels, pred_labels)\n",
    "        \n",
    "        if ari > best_ari:\n",
    "            best_ari = ari\n",
    "            \n",
    "        if nmi > best_nmi:\n",
    "            best_nmi = nmi\n",
    "    \n",
    "    return best_ari, best_nmi\n",
    "\n",
    "def calculate_knn_preservation(high_dim, low_dim, k=15):\n",
    "    \"\"\"\n",
    "    this, calculates KNN preservation between high-dimensional and low-dimensional spaces\n",
    "    \"\"\"\n",
    "    # find knn in high-dimensional space\n",
    "    high_nbrs = NearestNeighbors(n_neighbors=k+1).fit(high_dim)\n",
    "    high_indices = high_nbrs.kneighbors(high_dim, return_distance=False)\n",
    "    \n",
    "    # find knn in low-dimensional space\n",
    "    low_nbrs = NearestNeighbors(n_neighbors=k+1).fit(low_dim)\n",
    "    low_indices = low_nbrs.kneighbors(low_dim, return_distance=False)\n",
    "    \n",
    "    # calculate overlap\n",
    "    overlap_sum = 0\n",
    "    for i in range(high_dim.shape[0]):\n",
    "        high_set = set(high_indices[i, 1:])\n",
    "        low_set = set(low_indices[i, 1:])\n",
    "        overlap_sum += len(high_set.intersection(low_set))\n",
    "    \n",
    "    # preservation ratio\n",
    "    preservation = overlap_sum / (high_dim.shape[0] * k)\n",
    "    return preservation\n",
    "\n",
    "def evaluate_embeddings(adata, dr_results, method_name, cell_type_key):    \n",
    "    high_dim = adata.X\n",
    "    \n",
    "    if cell_type_key in adata.obs:\n",
    "        labels = adata.obs[cell_type_key].astype(str).values\n",
    "    else:\n",
    "        print(f\"Warning: {cell_type_key} not found in data. Skipping clustering metrics.\")\n",
    "        labels = None\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    if method_name == \"pca\":\n",
    "        for n_comp, data in dr_results.items():\n",
    "            embedding = data['embedding']\n",
    "            runtime = data['runtime']\n",
    "            \n",
    "            results[n_comp] = {'runtime': runtime}\n",
    "            \n",
    "            if labels is not None:\n",
    "                ari, nmi = evaluate_clustering_preservation(embedding, labels)\n",
    "                results[n_comp]['ari'] = ari\n",
    "                results[n_comp]['nmi'] = nmi\n",
    "            \n",
    "            results[n_comp]['knn_preservation'] = calculate_knn_preservation(high_dim, embedding)\n",
    "    \n",
    "    elif method_name == \"tsne\":\n",
    "        for perplexity, data in dr_results.items():\n",
    "            avg_runtime = np.mean(data['runtimes'])\n",
    "            results[perplexity] = {'runtime': avg_runtime}\n",
    "            \n",
    "            # average metrics across random seeds\n",
    "            ari_values = []\n",
    "            nmi_values = []\n",
    "            knn_values = []\n",
    "            \n",
    "            for i, embedding in enumerate(data['embeddings']):\n",
    "                if labels is not None:\n",
    "                    ari, nmi = evaluate_clustering_preservation(embedding, labels)\n",
    "                    ari_values.append(ari)\n",
    "                    nmi_values.append(nmi)\n",
    "                \n",
    "                knn_values.append(calculate_knn_preservation(high_dim, embedding))\n",
    "            \n",
    "            if labels is not None:\n",
    "                results[perplexity]['ari'] = np.mean(ari_values)\n",
    "                results[perplexity]['nmi'] = np.mean(nmi_values)\n",
    "            \n",
    "            results[perplexity]['knn_preservation'] = np.mean(knn_values)\n",
    "    \n",
    "    elif method_name == \"umap\":\n",
    "        for n_neighbors, min_dist_data in dr_results.items():\n",
    "            results[n_neighbors] = {}\n",
    "            \n",
    "            for min_dist, data in min_dist_data.items():\n",
    "                embedding = data['embedding']\n",
    "                runtime = data['runtime']\n",
    "                \n",
    "                results[n_neighbors][min_dist] = {'runtime': runtime}\n",
    "                \n",
    "                if labels is not None:\n",
    "                    ari, nmi = evaluate_clustering_preservation(embedding, labels)\n",
    "                    results[n_neighbors][min_dist]['ari'] = ari\n",
    "                    results[n_neighbors][min_dist]['nmi'] = nmi\n",
    "                \n",
    "                results[n_neighbors][min_dist]['knn_preservation'] = calculate_knn_preservation(high_dim, embedding)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33568569",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing clusters for PBMC dataset...\")\n",
    "\n",
    "if 'X_pca' not in pbmc_processed.obsm:\n",
    "    sc.pp.pca(pbmc_processed, n_comps=40, random_state=RANDOM_SEED)\n",
    "\n",
    "# knn on pca\n",
    "sc.pp.neighbors(pbmc_processed, n_neighbors=10, use_rep='X_pca')\n",
    "\n",
    "# Louvain\n",
    "sc.tl.louvain(pbmc_processed, resolution=0.5, random_state=RANDOM_SEED)\n",
    "print(\"PBMC Louvain clusters:\", pbmc_processed.obs['louvain'].unique())\n",
    "\n",
    "# Leiden\n",
    "sc.tl.leiden(pbmc_processed, resolution=0.5, random_state=RANDOM_SEED)\n",
    "print(\"PBMC Leiden clusters:\", pbmc_processed.obs['leiden'].unique())\n",
    "\n",
    "# Louvain vs Leiden\n",
    "ari_pbmc = adjusted_rand_score(\n",
    "    pbmc_processed.obs['louvain'].values,\n",
    "    pbmc_processed.obs['leiden'].values\n",
    ")\n",
    "print(f\"PBMC Louvain vs Leiden ARI: {ari_pbmc:.4f}\")\n",
    "\n",
    "print(\"\\nComputing clusters for trajectory dataset...\")\n",
    "\n",
    "if 'X_pca' not in trajectory_processed.obsm:\n",
    "    sc.pp.pca(trajectory_processed, n_comps=40, random_state=RANDOM_SEED)\n",
    "\n",
    "# knn on pca\n",
    "sc.pp.neighbors(trajectory_processed, n_neighbors=10, use_rep='X_pca')\n",
    "\n",
    "# Louvain\n",
    "if 'paul15_clusters' not in trajectory_processed.obs:\n",
    "    sc.tl.louvain(trajectory_processed, resolution=0.5, key_added='paul15_clusters', random_state=RANDOM_SEED)\n",
    "\n",
    "# Leiden\n",
    "sc.tl.leiden(trajectory_processed, resolution=0.5, key_added='paul15_clusters_leiden', random_state=RANDOM_SEED)\n",
    "\n",
    "# Louvain vs Leiden\n",
    "ari_trajectory = adjusted_rand_score(\n",
    "    trajectory_processed.obs['paul15_clusters'].values,\n",
    "    trajectory_processed.obs['paul15_clusters_leiden'].values\n",
    ")\n",
    "print(f\"Trajectory Louvain vs Leiden ARI: {ari_trajectory:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b3d7f1",
   "metadata": {},
   "source": [
    "Step 8: Running the Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371d1a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbmc_louvain_key = 'louvain'  \n",
    "pbmc_leiden_key = 'leiden'\n",
    "trajectory_louvain_key = 'paul15_clusters'\n",
    "trajectory_leiden_key = 'paul15_clusters_leiden'\n",
    "\n",
    "# PBMC with Louvain\n",
    "print(\"Evaluating PBMC dimensionality reduction results with Louvain clusters...\")\n",
    "pbmc_pca_eval_louvain = evaluate_embeddings(pbmc_processed, pbmc_pca_results, \"pca\", pbmc_louvain_key)\n",
    "pbmc_tsne_eval_louvain = evaluate_embeddings(pbmc_processed, pbmc_tsne_results, \"tsne\", pbmc_louvain_key)\n",
    "pbmc_umap_eval_louvain = evaluate_embeddings(pbmc_processed, pbmc_umap_results, \"umap\", pbmc_louvain_key)\n",
    "\n",
    "# PBMC with Leiden\n",
    "print(\"Evaluating PBMC dimensionality reduction results with Leiden clusters...\")\n",
    "pbmc_pca_eval_leiden = evaluate_embeddings(pbmc_processed, pbmc_pca_results, \"pca\", pbmc_leiden_key)\n",
    "pbmc_tsne_eval_leiden = evaluate_embeddings(pbmc_processed, pbmc_tsne_results, \"tsne\", pbmc_leiden_key)\n",
    "pbmc_umap_eval_leiden = evaluate_embeddings(pbmc_processed, pbmc_umap_results, \"umap\", pbmc_leiden_key)\n",
    "\n",
    "# trajectory with Louvain\n",
    "print(\"\\nEvaluating trajectory dimensionality reduction results with Louvain clusters...\")\n",
    "traj_pca_eval_louvain = evaluate_embeddings(trajectory_processed, trajectory_pca_results, \"pca\", trajectory_louvain_key)\n",
    "traj_tsne_eval_louvain = evaluate_embeddings(trajectory_processed, trajectory_tsne_results, \"tsne\", trajectory_louvain_key)\n",
    "traj_umap_eval_louvain = evaluate_embeddings(trajectory_processed, trajectory_umap_results, \"umap\", trajectory_louvain_key)\n",
    "\n",
    "# trajectory with Leiden\n",
    "print(\"\\nEvaluating trajectory dimensionality reduction results with Leiden clusters...\")\n",
    "traj_pca_eval_leiden = evaluate_embeddings(trajectory_processed, trajectory_pca_results, \"pca\", trajectory_leiden_key)\n",
    "traj_tsne_eval_leiden = evaluate_embeddings(trajectory_processed, trajectory_tsne_results, \"tsne\", trajectory_leiden_key)\n",
    "traj_umap_eval_leiden = evaluate_embeddings(trajectory_processed, trajectory_umap_results, \"umap\", trajectory_leiden_key)\n",
    "\n",
    "print(\"All evaluations completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad7f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute clusters for both datasets\n",
    "# print(\"Computing clusters for PBMC dataset...\")\n",
    "# sc.pp.neighbors(pbmc_processed, n_neighbors=10, n_pcs=40)\n",
    "# sc.tl.louvain(pbmc_processed, resolution=0.5)\n",
    "# print(\"PBMC cell types:\", pbmc_processed.obs['louvain'].unique())\n",
    "\n",
    "# print(\"\\nComputing clusters for trajectory dataset...\")\n",
    "# sc.pp.neighbors(trajectory_processed, n_neighbors=10, n_pcs=40)\n",
    "# if 'paul15_clusters' not in trajectory_processed.obs:\n",
    "#     # Create clusters if the ground truth isn't available\n",
    "#     sc.tl.louvain(trajectory_processed, resolution=0.5, key_added='paul15_clusters')\n",
    "\n",
    "# # Check available columns for reference\n",
    "# print(\"\\nAvailable columns in PBMC data:\")\n",
    "# print(list(pbmc_processed.obs.columns))\n",
    "# print(\"\\nAvailable columns in trajectory data:\")\n",
    "# print(list(trajectory_processed.obs.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880fb062",
   "metadata": {},
   "source": [
    "Step 9: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eae6006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_results(adata, pca_results, cell_type_key, title_prefix=\"\"):\n",
    "    n_plots = len(pca_results)\n",
    "    fig, axes = plt.subplots(2, n_plots, figsize=(5*n_plots, 10))\n",
    "    \n",
    "    for i, (n_comp, result) in enumerate(pca_results.items()):\n",
    "        # variance plot\n",
    "        variance_ratio = result['variance_ratio']\n",
    "        cumulative_variance = np.cumsum(variance_ratio)\n",
    "        axes[0, i].plot(range(1, len(variance_ratio)+1), cumulative_variance, 'o-')\n",
    "        axes[0, i].axhline(y=0.8, color='r', linestyle='--', alpha=0.5)\n",
    "        axes[0, i].set_xlabel('Number of components')\n",
    "        axes[0, i].set_ylabel('Cumulative explained variance')\n",
    "        axes[0, i].set_title(f'{title_prefix} PCA n_comp={n_comp}')\n",
    "        \n",
    "        # scatter plot\n",
    "        embedding = result['embedding']\n",
    "        temp = ad.AnnData(X=adata.X)\n",
    "        temp.obs = adata.obs\n",
    "        temp.obsm['X_pca'] = embedding\n",
    "        \n",
    "        sc.pl.pca(temp, color=cell_type_key, ax=axes[1, i], show=False)\n",
    "        axes[1, i].set_title(f'Runtime: {result[\"runtime\"]:.2f} sec')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_tsne_results(adata, tsne_results, cell_type_key, title_prefix=\"\"):\n",
    "    n_plots = len(tsne_results)\n",
    "    fig, axes = plt.subplots(1, n_plots, figsize=(5*n_plots, 5))\n",
    "    \n",
    "    for i, (perplexity, result) in enumerate(tsne_results.items()):\n",
    "        # first seed for plotting\n",
    "        embedding = result['embeddings'][0]\n",
    "        runtime = result['runtimes'][0]\n",
    "        \n",
    "        temp = ad.AnnData(X=adata.X)\n",
    "        temp.obs = adata.obs\n",
    "        temp.obsm['X_tsne'] = embedding\n",
    "        \n",
    "        sc.pl.tsne(temp, color=cell_type_key, ax=axes[i], show=False)\n",
    "        axes[i].set_title(f'{title_prefix} t-SNE perp={perplexity}\\nRuntime: {runtime:.2f} sec')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_umap_results(adata, umap_results, cell_type_key, title_prefix=\"\"):\n",
    "    n_neighbors_list = list(umap_results.keys())\n",
    "    min_dist_list = list(umap_results[n_neighbors_list[0]].keys())\n",
    "    \n",
    "    fig, axes = plt.subplots(len(n_neighbors_list), len(min_dist_list), \n",
    "                             figsize=(5*len(min_dist_list), 5*len(n_neighbors_list)))\n",
    "    \n",
    "    for i, n_neighbors in enumerate(n_neighbors_list):\n",
    "        for j, min_dist in enumerate(min_dist_list):\n",
    "            result = umap_results[n_neighbors][min_dist]\n",
    "            embedding = result['embedding']\n",
    "            runtime = result['runtime']\n",
    "            \n",
    "            temp = ad.AnnData(X=adata.X)\n",
    "            temp.obs = adata.obs\n",
    "            temp.obsm['X_umap'] = embedding\n",
    "            \n",
    "            ax = axes[i, j] if len(n_neighbors_list) > 1 else axes[j]\n",
    "            sc.pl.umap(temp, color=cell_type_key, ax=ax, show=False)\n",
    "            ax.set_title(f'{title_prefix} UMAP n_neigh={n_neighbors}, min_d={min_dist}\\nRuntime: {runtime:.2f} sec')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# we use Leiden since it is generally considered better\n",
    "pbmc_cell_type_key = pbmc_leiden_key\n",
    "trajectory_cell_type_key = trajectory_leiden_key\n",
    "\n",
    "# PBMC\n",
    "plot_pca_results(pbmc_processed, pbmc_pca_results, pbmc_cell_type_key, \"PBMC\")\n",
    "plot_tsne_results(pbmc_processed, pbmc_tsne_results, pbmc_cell_type_key, \"PBMC\")\n",
    "plot_umap_results(pbmc_processed, pbmc_umap_results, pbmc_cell_type_key, \"PBMC\")\n",
    "\n",
    "# trajectory\n",
    "plot_pca_results(trajectory_processed, trajectory_pca_results, trajectory_cell_type_key, \"Trajectory\")\n",
    "plot_tsne_results(trajectory_processed, trajectory_tsne_results, trajectory_cell_type_key, \"Trajectory\")\n",
    "plot_umap_results(trajectory_processed, trajectory_umap_results, trajectory_cell_type_key, \"Trajectory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2280bb",
   "metadata": {},
   "source": [
    "Step 10: Compare Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ef186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_summary_with_clustering_comparison(\n",
    "    # Louvain evaluations\n",
    "    pbmc_pca_eval_louvain, pbmc_tsne_eval_louvain, pbmc_umap_eval_louvain,\n",
    "    traj_pca_eval_louvain, traj_tsne_eval_louvain, traj_umap_eval_louvain,\n",
    "    # Leiden evaluations\n",
    "    pbmc_pca_eval_leiden, pbmc_tsne_eval_leiden, pbmc_umap_eval_leiden,\n",
    "    traj_pca_eval_leiden, traj_tsne_eval_leiden, traj_umap_eval_leiden\n",
    "):\n",
    "    \"\"\"summary of performance metrics for all methods and clustering algorithms\"\"\"\n",
    "    \n",
    "    def extract_metrics(eval_dict, method, dataset, clustering_algorithm):\n",
    "        metrics_list = []\n",
    "        \n",
    "        if method == \"PCA\":\n",
    "            for n_comp, metrics in eval_dict.items():\n",
    "                metrics_list.append({\n",
    "                    'Method': method,\n",
    "                    'Dataset': dataset,\n",
    "                    'Parameters': f'n_comp={n_comp}',\n",
    "                    'Clustering_Algorithm': clustering_algorithm,\n",
    "                    'ARI': metrics.get('ari', np.nan),\n",
    "                    'NMI': metrics.get('nmi', np.nan),\n",
    "                    'KNN_Preservation': metrics.get('knn_preservation', np.nan),\n",
    "                    'Runtime_sec': metrics['runtime']\n",
    "                })\n",
    "        \n",
    "        elif method == \"t-SNE\":\n",
    "            for perp, metrics in eval_dict.items():\n",
    "                metrics_list.append({\n",
    "                    'Method': method,\n",
    "                    'Dataset': dataset,\n",
    "                    'Parameters': f'perplexity={perp}',\n",
    "                    'Clustering_Algorithm': clustering_algorithm,\n",
    "                    'ARI': metrics.get('ari', np.nan),\n",
    "                    'NMI': metrics.get('nmi', np.nan),\n",
    "                    'KNN_Preservation': metrics.get('knn_preservation', np.nan),\n",
    "                    'Runtime_sec': metrics['runtime']\n",
    "                })\n",
    "        \n",
    "        elif method == \"UMAP\":\n",
    "            for n_neigh, min_dist_data in eval_dict.items():\n",
    "                for min_dist, metrics in min_dist_data.items():\n",
    "                    metrics_list.append({\n",
    "                        'Method': method,\n",
    "                        'Dataset': dataset,\n",
    "                        'Parameters': f'n_neighbors={n_neigh}, min_dist={min_dist}',\n",
    "                        'Clustering_Algorithm': clustering_algorithm,\n",
    "                        'ARI': metrics.get('ari', np.nan),\n",
    "                        'NMI': metrics.get('nmi', np.nan),\n",
    "                        'KNN_Preservation': metrics.get('knn_preservation', np.nan),\n",
    "                        'Runtime_sec': metrics['runtime']\n",
    "                    })\n",
    "                    \n",
    "        return metrics_list\n",
    "    \n",
    "    # metrics for Louvain\n",
    "    pbmc_pca_metrics_louvain = extract_metrics(pbmc_pca_eval_louvain, \"PCA\", \"PBMC\", \"Louvain\")\n",
    "    pbmc_tsne_metrics_louvain = extract_metrics(pbmc_tsne_eval_louvain, \"t-SNE\", \"PBMC\", \"Louvain\")\n",
    "    pbmc_umap_metrics_louvain = extract_metrics(pbmc_umap_eval_louvain, \"UMAP\", \"PBMC\", \"Louvain\")\n",
    "    \n",
    "    traj_pca_metrics_louvain = extract_metrics(traj_pca_eval_louvain, \"PCA\", \"Trajectory\", \"Louvain\")\n",
    "    traj_tsne_metrics_louvain = extract_metrics(traj_tsne_eval_louvain, \"t-SNE\", \"Trajectory\", \"Louvain\")\n",
    "    traj_umap_metrics_louvain = extract_metrics(traj_umap_eval_louvain, \"UMAP\", \"Trajectory\", \"Louvain\")\n",
    "    \n",
    "    # metrics for Leiden\n",
    "    pbmc_pca_metrics_leiden = extract_metrics(pbmc_pca_eval_leiden, \"PCA\", \"PBMC\", \"Leiden\")\n",
    "    pbmc_tsne_metrics_leiden = extract_metrics(pbmc_tsne_eval_leiden, \"t-SNE\", \"PBMC\", \"Leiden\")\n",
    "    pbmc_umap_metrics_leiden = extract_metrics(pbmc_umap_eval_leiden, \"UMAP\", \"PBMC\", \"Leiden\")\n",
    "    \n",
    "    traj_pca_metrics_leiden = extract_metrics(traj_pca_eval_leiden, \"PCA\", \"Trajectory\", \"Leiden\")\n",
    "    traj_tsne_metrics_leiden = extract_metrics(traj_tsne_eval_leiden, \"t-SNE\", \"Trajectory\", \"Leiden\")\n",
    "    traj_umap_metrics_leiden = extract_metrics(traj_umap_eval_leiden, \"UMAP\", \"Trajectory\", \"Leiden\")\n",
    "    \n",
    "    # combine all\n",
    "    all_metrics = (\n",
    "        pbmc_pca_metrics_louvain + pbmc_tsne_metrics_louvain + pbmc_umap_metrics_louvain +\n",
    "        traj_pca_metrics_louvain + traj_tsne_metrics_louvain + traj_umap_metrics_louvain +\n",
    "        pbmc_pca_metrics_leiden + pbmc_tsne_metrics_leiden + pbmc_umap_metrics_leiden +\n",
    "        traj_pca_metrics_leiden + traj_tsne_metrics_leiden + traj_umap_metrics_leiden\n",
    "    )\n",
    "    \n",
    "    metrics_df = pd.DataFrame(all_metrics)\n",
    "    \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad29e54",
   "metadata": {},
   "source": [
    "Visualize the comparison between Louvain and Leiden clustering!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff40d567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clustering_algorithm_comparison(performance_df):\n",
    "    \"\"\"performance metrics between Louvain and Leiden\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    # ARI\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.boxplot(x='Method', y='ARI', hue='Clustering_Algorithm', \n",
    "                data=performance_df, palette=['#3498db', '#e74c3c'])\n",
    "    plt.title('Clustering Quality (ARI) by Algorithm')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # NMI\n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.boxplot(x='Method', y='NMI', hue='Clustering_Algorithm', \n",
    "                data=performance_df, palette=['#3498db', '#e74c3c'])\n",
    "    plt.title('Clustering Quality (NMI) by Algorithm')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # dataset-specific comparison:PBMC\n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.boxplot(x='Method', y='ARI', hue='Clustering_Algorithm', \n",
    "                data=performance_df[performance_df['Dataset'] == 'PBMC'], \n",
    "                palette=['#3498db', '#e74c3c'])\n",
    "    plt.title('PBMC Dataset - ARI by Clustering Algorithm')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # dataset-specific comparison: Trajectory\n",
    "    plt.subplot(2, 2, 4)\n",
    "    sns.boxplot(x='Method', y='ARI', hue='Clustering_Algorithm', \n",
    "                data=performance_df[performance_df['Dataset'] == 'Trajectory'], \n",
    "                palette=['#3498db', '#e74c3c'])\n",
    "    plt.title('Trajectory Dataset - ARI by Clustering Algorithm')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.suptitle('Louvain vs Leiden Clustering Performance', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a231661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined performance summary\n",
    "performance_df_combined = create_performance_summary_with_clustering_comparison(\n",
    "    # Louvain\n",
    "    pbmc_pca_eval_louvain, pbmc_tsne_eval_louvain, pbmc_umap_eval_louvain,\n",
    "    traj_pca_eval_louvain, traj_tsne_eval_louvain, traj_umap_eval_louvain,\n",
    "    # Leiden\n",
    "    pbmc_pca_eval_leiden, pbmc_tsne_eval_leiden, pbmc_umap_eval_leiden,\n",
    "    traj_pca_eval_leiden, traj_tsne_eval_leiden, traj_umap_eval_leiden\n",
    ")\n",
    "\n",
    "print(\"Performance Summary with Clustering Algorithm Comparison:\")\n",
    "display(performance_df_combined)\n",
    "\n",
    "plot_clustering_algorithm_comparison(performance_df_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c3f84a",
   "metadata": {},
   "source": [
    "Step 11: Save Results and Create Environment Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving figures and results\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "performance_df_combined.to_csv('results/performance_metrics.csv', index=False)\n",
    "\n",
    "# environment.yml file\n",
    "with open('environment.yml', 'w') as f:\n",
    "    f.write(\"\"\"name: scrna_dimred\n",
    "channels:\n",
    "  - conda-forge\n",
    "  - bioconda\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.9\n",
    "  - numpy\n",
    "  - pandas\n",
    "  - matplotlib\n",
    "  - seaborn\n",
    "  - scikit-learn\n",
    "  - umap-learn\n",
    "  - scanpy\n",
    "  - anndata\n",
    "  - jupyterlab\n",
    "  - nb_conda_kernels\n",
    "  - pip\n",
    "  - pip:\n",
    "    - leidenalg\n",
    "\"\"\")\n",
    "\n",
    "print(\"Results saved and environment.yml file created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7242107",
   "metadata": {},
   "source": [
    "Step 12: Generate a Summary and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec12904",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "## Summary of Findings\n",
    "\n",
    "1. **PCA** \n",
    "   - Fastest runtime, but also suprisingly -somehow- best? clustering preservation\n",
    "   - Good at preserving global structure\n",
    "   - Best for initial dimensionality reduction before other methods\n",
    "\n",
    "2. **t-SNE**\n",
    "   - Slowest runtime, especially for larger datasets\n",
    "   - Excellent at preserving local structure and clusters\n",
    "   - Performance highly sensitive to perplexity parameter\n",
    "   - Tends to fragment continuous trajectories ????\n",
    "\n",
    "3. **UMAP**\n",
    "   - Moderate runtime, faster than t-SNE\n",
    "   - Good balance between local and global structure preservation\n",
    "   - Best performance on the trajectory dataset\n",
    "   - More stable across parameter configurations than t-SNE\n",
    "\n",
    "## Optimal Parameters\n",
    "\n",
    "- **PCA**: 50 components captured arround 30-40 variance\n",
    "- **t-SNE**: Perplexity of 30 worked best across both datasets\n",
    "- **UMAP**: n_neighbors=15, min_dist=0.1 provided the best balance between preserving clusters and trajectories\n",
    "\n",
    "## Recommendations\n",
    "\n",
    "- For exploratory analysis: Start with PCA, then UMAP\n",
    "- For cluster visualization: UMAP with smaller min_dist\n",
    "- For trajectory analysis: UMAP with larger n_neighbors\n",
    "- For best computational efficiency: PCA followed by UMAP\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plots show only ~30-35% variance explained with 100 components.\n",
    "\n",
    "Revise clustering performance claims: PCA shows the highest clustering preservation, not the lowest as stated. This contradicts your conclusion but shows an interesting finding - PCA's linear projections maintain more of the original structure.\n",
    "\n",
    "Parameter recommendations should be dataset-specific:\n",
    "\n",
    "For PBMC: Higher n_neighbors (30-50) for UMAP\n",
    "For trajectory: n_neighbors=15, min_dist=0.1 is indeed optimal\n",
    "Explain PCA's strong performance: PCA works well for clustering despite simpler visualization - it preserved* global distances better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cc2d5c",
   "metadata": {},
   "source": [
    "Step 13: Generate a Presentation Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65453d6d",
   "metadata": {},
   "source": [
    "# Presentation Script\n",
    "\n",
    "## Introduction (3 min)\n",
    "- Single-cell RNA-seq allows us to profile thousands of individual cells\n",
    "- Dimensionality reduction is essential for visualization and analysis\n",
    "- This project compares PCA, t-SNE, and UMAP on two distinct datasets\n",
    "\n",
    "## Methods (5-7 min)\n",
    "- Used Python (scanpy) for implementation\n",
    "- Analyzed PBMC dataset (discrete cell types) and developmental trajectory\n",
    "- Applied preprocessing pipeline: QC, normalization, feature selection\n",
    "- Compared methods across multiple parameter settings\n",
    "- Evaluated using: cluster preservation for both Louvain and Leiden (ARI/NMI), structure preservation (KNN), runtime\n",
    "\n",
    "## Results - PBMC Dataset (2 min)\n",
    "- PCA: Explained ~40% variance with 50-100 components\n",
    "- t-SNE: Best separates distinct cell types, especially with perplexity=30\n",
    "- UMAP: Balanced performance, faster than t-SNE\n",
    "- Show visualizations and performance metrics\n",
    "\n",
    "## Results - Trajectory Dataset (2 min)\n",
    "- PCA: Captures linear aspects of differentiation, but limited in 2D\n",
    "- t-SNE: Fragments continuous structures at low perplexity\n",
    "- UMAP: Best preserves developmental trajectory, especially with higher n_neighbors\n",
    "- Show visualizations and performance metrics\n",
    "\n",
    "## Conclusions (2 min)\n",
    "- Each method has strengths and weaknesses\n",
    "- PCA is best for initial dimensionality reduction\n",
    "- t-SNE excels at visualizing discrete clusters\n",
    "- UMAP provides the best balance for most scRNA-seq applications\n",
    "- Optimal workflow: PCA → UMAP with parameters tuned to analysis goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c74ccf3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
